{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Based on tutorial: https://machinelearningmastery.com/random-forest-ensemble-in-python/\n",
    "#Run this code before you can classify\n",
    "\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the models we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "#Import mathplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load in the dataset\n",
    "features = pd.read_csv('heloc_dataset_v1.csv')\n",
    "feature_names = features.columns\n",
    "\n",
    "#the columns that stores the labels\n",
    "labelDimension = \"RiskPerformance\"\n",
    "feature_names = feature_names.drop(labelDimension)\n",
    "\n",
    "\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features[labelDimension])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop(labelDimension, axis = 1)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Split the data into training and testing sets (heavily overfit on provided dataset to get as close as possible to the original model)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.30)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "\n",
    "def build_rf_model(train_features, train_labels, features, labels):\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = 1500)\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    #evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1)\n",
    "    n_scores = cross_val_score(rf, features, labels, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    print(\"done!\")\n",
    "    print(\"evaluating:\")\n",
    "\n",
    "    # report performance\n",
    "    print(n_scores)\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#build a random forest classifier\n",
    "rf_model = build_rf_model(train_features, train_labels, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #get the first datarow of the dataset\n",
    "# row = features.loc[0,:]\n",
    "\n",
    "# #remove the label column (first column)\n",
    "# instance = row[1:len(row)]\n",
    "\n",
    "# # Use the forest's predict method on the test data\n",
    "# prediction = rf_model.predict(instance.to_numpy().reshape(1,-1))\n",
    "\n",
    "# #print prediction\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_kNN_model(train_features, train_labels, features, labels):\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    knn = KNeighborsClassifier(n_estimators = 1500)\n",
    "    # Train the model on training data\n",
    "    knn.fit(train_features, train_labels)\n",
    "\n",
    "    #evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1)\n",
    "    n_scores = cross_val_score(knn, features, labels, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    print(\"done!\")\n",
    "    print(\"evaluating:\")\n",
    "\n",
    "    # report performance\n",
    "    print(n_scores)\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a kNN\n",
    "rf_model = build_rf_model(train_features, train_labels, features, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
